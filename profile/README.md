# ğŸ™ï¸ VIVID Avatar Team @ ByteDance

We are the **VIVID** (**V**oice **I**ntegrated **V**ideo **I**mmersive **D**igital) Avatar Team at ByteDance, dedicated to **cutting-edge research on audio-visual digital human generation**.

---

## ğŸš€ Research Projects

### ğŸµ Audio Synthesis
- **MegaTTS3**  
  *Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis*  
  [ğŸ“„ Paper](https://arxiv.org/abs/2502.18924) | [ğŸ’» Code](https://github.com/bytedance/MegaTTS3)

- **Text-to-Speech Synthesis with Chain-of-Thought Style Reasoning**

- **Make-An-Audio 2**  
  *Temporal-Enhanced Text-to-Audio Generation*  
  [ğŸ“„ Paper](https://arxiv.org/abs/2305.18474) | [ğŸ’» Code](https://github.com/bytedance/Make-An-Audio-2)

---

### ğŸ¥ Video Generation
- **InfinityHuman**  
  *Towards Long-Term Audio-Driven Human Animation*

- **HumanDiT**  
  *Pose-Guided Diffusion Transformer for Long-form Human Motion Video Generation*  
  [ğŸ“„ Paper](https://arxiv.org/abs/2502.04847) | [ğŸŒ Demo Page](https://agnjason.github.io/HumanDiT-page/)

- **DiTalker**  
  *Fast and Expressive Audio-Driven Talking Face Generation with Dual Diffusion Transformers*

- **MimicTalk** (_NeurIPS 2024_)  
  *Mimicking a Personalized and Expressive 3D Talking Face in Minutes*  
  [ğŸ“„ Paper](https://arxiv.org/abs/2410.06734) | [ğŸ’» Code](https://github.com/yerfor/MimicTalk)

- **Real3D-Portrait** (_ICLR 2024 Spotlight_)  
  *One-shot Realistic 3D Talking Portrait Synthesis*  
  [ğŸ“„ Paper](https://arxiv.org/abs/2401.08503) | [ğŸ’» Code](https://github.com/yerfor/Real3DPortrait)

- **Ada-TTA**  
  *Towards Adaptive High-Quality Text-to-Talking Avatar Synthesis*

---

ğŸ’¡ *We are continuously exploring the boundaries of digital human technology â€” from lifelike speech synthesis to expressive, long-form video avatars.*